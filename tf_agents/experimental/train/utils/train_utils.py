# coding=utf-8
# Copyright 2018 The TF-Agents Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Lint as: python3
"""Utils for distributed training using Actor/Learner API."""

import time
from typing import Callable, Text, Tuple

from absl import logging

import tensorflow.compat.v2 as tf

from tf_agents.agents import tf_agent
from tf_agents.typing import types
from tf_agents.utils import lazy_loader

# Lazy loading since not all users have the reverb package installed.
reverb = lazy_loader.LazyLoader('reverb', globals(), 'reverb')


def create_train_step() -> tf.Variable:
  return tf.Variable(
      0,
      trainable=False,
      dtype=tf.int64,
      aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA,
      shape=())


def create_staleness_metrics_after_train_step_fn(
    train_step: tf.Variable,
    train_steps_per_policy_update: int = 1
) -> Callable[
    [Tuple[types.NestedTensor,
           types.ReverbSampleInfo], tf_agent.LossInfo], None]:
  """Creates an `after_train_step_fn` that computes staleness summaries.

  Staleness, in this context, means that the observation was generated by a
  policy that is older than the recently outputed policy.
  Assume that observation train step is stored as Reverb priorities.

  Args:
    train_step: The current train step.
    train_steps_per_policy_update: Number of train iterations to perform between
      two policy updates.

  Returns:
    The created `after_train_step_fn`.
  """

  def after_train_step_fn(experience, loss_info):
    del loss_info  # Unused.
    _, sample_info = experience

    # Get the train step in which the experience was observed. This is stored as
    # Reverb priority.
    # TODO(b/168426331): Check sample info version.
    observation_generation_train_step = tf.cast(
        sample_info.priority, dtype=tf.int64)

    # Get the train step corresponding to the latest outputed policy.
    # Policy is written in every `train_steps_per_policy_update` step, so we
    # normalize the value of `train_step` accordingly.
    on_policy_train_step = tf.cast(
        train_step / train_steps_per_policy_update,
        dtype=tf.int64) * train_steps_per_policy_update

    # An observation is off-policy if its train step delta is greater than 0.
    observation_train_step_delta = (
        on_policy_train_step - observation_generation_train_step)
    max_train_step_delta = tf.reduce_max(observation_train_step_delta)
    max_policy_update_delta = tf.cast(
        max_train_step_delta / train_steps_per_policy_update, dtype=tf.int64)
    num_stale_observations = tf.reduce_sum(
        tf.cast(observation_train_step_delta > 0, tf.int64))

    # Break out from local name scopes (e.g. the ones intrdouced by while loop).
    with tf.name_scope(''):
      # Write the summaries for the first replica.
      tf.summary.scalar(
          name='staleness/max_train_step_delta_in_batch',
          data=max_train_step_delta,
          step=train_step)
      tf.summary.scalar(
          name='staleness/max_policy_update_delta_in_batch',
          data=max_policy_update_delta,
          step=train_step)
      tf.summary.scalar(
          name='staleness/num_stale_obserations_in_batch',
          data=num_stale_observations,
          step=train_step)

  return after_train_step_fn


# TODO(b/142821173): Test train_utils `wait_for_files` function.
def wait_for_file(file_path: Text, sleep_time_secs: int,
                  num_retries: int) -> Text:
  """Blocks until the file at `file_path` becomes available.

  Args:
    file_path: The path to the file that we are waiting for.
    sleep_time_secs: Number of time in seconds slept between retries.
    num_retries: Number of times the existence of the file is checked.

  Returns:
    The original `file_path`.

  Raises:
    TimeoutError: If the file does not become available during the number of
      trials.
  """

  def _is_file_missing(file_path=file_path):
    """Checks if the file is (still) missing, i.e. more wait is necessary."""
    try:
      stat = tf.io.gfile.stat(file_path)
    except tf.errors.NotFoundError:
      return True
    return stat.length <= 0

  wait_for_predicate(
      wait_predicate_fn=_is_file_missing,
      sleep_time_secs=sleep_time_secs,
      num_retries=num_retries)

  return file_path


# TODO(b/142821173): Test train_utils `wait_for_predicate` function.
def wait_for_predicate(wait_predicate_fn: Callable[[], bool],
                       sleep_time_secs: int, num_retries: int) -> None:
  """Blocks while `wait_predicate_fn` is returning `True`.

  The callable `wait_predicate_fn` indicates if waiting is still needed by
  returning `True`. Once the condition that we wanted to wait for met, the
  callable should return `False` denoting that the execution can continue.

  Args:
    wait_predicate_fn: A callable returning a bool. Blocks while it is returning
      `True`. Returns if it becomes `False`.
    sleep_time_secs: Number of time in seconds slept between retries.
    num_retries: Number of times the existence of the file is checked.

  Raises:
    TimeoutError: If the `wait_predicate_fn` does not become `False` during the
      number of trials.
  """
  retry = 0
  while (num_retries is None or retry < num_retries) and wait_predicate_fn():
    if sleep_time_secs > 0:
      logging.info(
          'Waiting for `wait_predicate_fn`. Block execution. Sleeping for %d '
          'seconds.', sleep_time_secs)
      time.sleep(sleep_time_secs)
    retry += 1

  if wait_predicate_fn():
    raise TimeoutError(
        'The wait predicate did not return `False` after {} retries waiting {} '
        'seconds between retries.'.format(num_retries, sleep_time_secs))

  logging.info('The `wait_predicate_fn` returned `False`. Continue execution.')
